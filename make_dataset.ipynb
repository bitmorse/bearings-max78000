{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already downloaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "DATASET_NAME = \"ims_bearings\"\n",
    "DATASET_URL = \"https://data.nasa.gov/download/brfb-gzcv/application/zip\"\n",
    "TEMP_PATH = os.path.expanduser('~/Downloads') + \"/dataset/\"\n",
    "\n",
    "# Download the dataset to temp\n",
    "os.system(\"mkdir -p \" + TEMP_PATH)\n",
    "\n",
    "#check if exists first\n",
    "ZIPPED = TEMP_PATH + DATASET_NAME + \".zip\"\n",
    "if os.path.exists(ZIPPED):\n",
    "    print(\"Dataset already downloaded\")\n",
    "else:\n",
    "    #unzip it inside its own folder\n",
    "    os.system(\"wget -q -O \" + ZIPPED + \" \" + DATASET_URL)\n",
    "    os.system(\"unzip \" + ZIPPED + \" -d \" + TEMP_PATH + DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1st_test.rar\n",
      "2\n",
      "2nd_test.rar\n",
      "3\n",
      "3rd_test.rar\n",
      "Readme Document for IMS Bearing Data.pdf\n"
     ]
    }
   ],
   "source": [
    "IMS_PATH = TEMP_PATH + DATASET_NAME + \"/IMS/\"\n",
    "os.chdir(IMS_PATH)\n",
    "os.system(\"ls\")\n",
    "\n",
    "#check if unrar exists\n",
    "if not os.path.exists(\"/usr/bin/unrar\"):\n",
    "    print(\"unrar not installed\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if not os.path.exists(IMS_PATH + \"1/\"):\n",
    "    os.system(\"mkdir -p \" + IMS_PATH + \"1/\")\n",
    "    os.system(\"mkdir -p \" + IMS_PATH + \"2/\")\n",
    "    os.system(\"mkdir -p \" + IMS_PATH + \"3/\")\n",
    "\n",
    "    os.system(\"unrar e \" + TEMP_PATH + DATASET_NAME + \"/IMS/1st_test.rar 1/\")\n",
    "    os.system(\"unrar e \" + TEMP_PATH + DATASET_NAME + \"/IMS/2nd_test.rar 2/\")\n",
    "    os.system(\"unrar e \" + TEMP_PATH + DATASET_NAME + \"/IMS/3rd_test.rar 3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_nparray(data, factor=2):\n",
    "    \"\"\"\n",
    "    Downsamples a numpy array by a given factor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input data array.\n",
    "    factor : int\n",
    "        Factor by which to downsample the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    downsampled_data : array_like\n",
    "        Downsampled data array.\n",
    "    \"\"\"\n",
    "    downsampled_data = data[::factor]\n",
    "    \n",
    "    #normalise \n",
    "    downsampled_data = downsampled_data - np.mean(downsampled_data)\n",
    "    downsampled_data = downsampled_data / np.std(downsampled_data)\n",
    "    \n",
    "    return downsampled_data\n",
    "    \n",
    "\n",
    "def create_windows(data, window_length=128, overlap_length=32, window_type='rectangular'):\n",
    "    \"\"\"\n",
    "    Creates a list of windows from a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : array_like\n",
    "        Input data array.\n",
    "    window_length : int\n",
    "        Length of the window.\n",
    "    overlap_length : int\n",
    "        Length of the overlap between windows.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    windows : list\n",
    "        List of windows.\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    for i in range(0, len(data) - window_length, window_length-overlap_length):\n",
    "        if window_type == 'hamming':\n",
    "            coeffs = np.hamming(window_length)\n",
    "        else:\n",
    "            coeffs = np.ones(window_length)\n",
    "            \n",
    "        windows.append(coeffs * data[i:i + window_length].flatten())\n",
    "    return np.array(windows)\n",
    "    \n",
    "def create_stft_spectrogram(windows, fft_length=128):\n",
    "    \"\"\"\n",
    "    Creates a spectrogram from a list of windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    windows : list\n",
    "        List of windows.\n",
    "    fft_length : int\n",
    "        Length of the FFT.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spectrogram : array_like\n",
    "        Spectrogram.\n",
    "    \"\"\"\n",
    "    spectrogram = np.abs(np.fft.fft(windows, n=fft_length, axis=1))**2/fft_length #psd\n",
    "    \n",
    "    #keep only the last half of the fft (the other half is a mirror image)\n",
    "    spectrogram = spectrogram[:, :fft_length // 2]\n",
    "    \n",
    "    spectrogram = spectrogram.T\n",
    "\n",
    "    return spectrogram\n",
    "\n",
    "\n",
    "def create_stft_spectrograms(windows, stft_overlap=10, stft_window_length=50, fft_length=128):\n",
    "    \"\"\"\n",
    "    Creates a list of spectrogram images from a list of all windows. The windows are first grouped into new windows. \n",
    "    Those new windows are then used to create the spectrograms.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    windows : list\n",
    "        List of all windows that shall be grouped.\n",
    "    overlap : int\n",
    "        Length of the overlap between window groups.\n",
    "    stft_window_length : int\n",
    "        Length of the window group for the STFT.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spectrograms : list\n",
    "        List of spectrograms.\n",
    "    \"\"\"\n",
    "    spectrograms = []\n",
    "    for i in range(0, len(windows) - stft_window_length, stft_window_length-stft_overlap):\n",
    "        #sliding window over the windows by overlap\n",
    "        current_window = windows[i:i + stft_window_length]\n",
    "        \n",
    "        spectrograms.append(create_stft_spectrogram(current_window, fft_length=fft_length))\n",
    "    return np.array(spectrograms)\n",
    "    \n",
    "    \n",
    "def plot_spectrogram(spectrogram):\n",
    "    \"\"\"\n",
    "    Plots a spectrogram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spectrogram : array_like\n",
    "        Spectrogram.\n",
    "    \"\"\"\n",
    "    plt.imshow(spectrogram)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_cwru_to_spectrogram(mat_path, column_name=None, window_type='hamming', stft_window_length=50, fft_length=128, window_overlap=32, stft_overlap=10):\n",
    "    \"\"\"\n",
    "    Converts a .mat file from the CWRU dataset to a spectrogram.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mat_path : str\n",
    "        Path to the .mat file.\n",
    "    column_name : str\n",
    "        Name of the column in the .mat file that contains the data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    spectrograms : list\n",
    "        List of spectrograms.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(mat_path)\n",
    "    if column_name:\n",
    "        data = downsample_nparray(mat[column_name])\n",
    "    else:\n",
    "        #take the first column that ends with DE_time\n",
    "        data = downsample_nparray(mat[[key for key in mat.keys() if key.endswith('DE_time')][0]])\n",
    "        \n",
    "    windows = create_windows(data, window_type=window_type, window_length=stft_window_length, overlap_length=window_overlap)\n",
    "    spectrograms = create_stft_spectrograms(windows, stft_overlap=stft_overlap, stft_window_length=stft_window_length, fft_length=fft_length)\n",
    "    return spectrograms\n",
    "\n",
    "\n",
    "def convert_nasa_experiments_to_numpy(ims_path=IMS_PATH):\n",
    "    experiment_files = {\"1\": os.listdir(ims_path + \"1/\"), \"2\": os.listdir(ims_path + \"2/\"), \"3\": os.listdir(ims_path + \"3/\")}\n",
    "    experiments_data = {\"1\": {\"bearing3_values\":[],\"bearing3_keys\":[]} , \"2\": {\"bearing3_values\":[],\"bearing3_keys\":[]}, \"3\": {\"bearing3_values\":[],\"bearing3_keys\":[]}}\n",
    "    \n",
    "    #sort experiment files by name\n",
    "    for experiment in experiment_files:\n",
    "        experiment_files[experiment] = sorted(experiment_files[experiment])\n",
    "        \n",
    "    \n",
    "    for experiment in experiment_files:\n",
    "        i=0\n",
    "        for file in experiment_files[experiment]:\n",
    "            #print(\"Converting exp %s file %s\" % (experiment, file))\n",
    "            #load the data in the file\n",
    "            data = np.loadtxt(ims_path + experiment + \"/\" + file)\n",
    "            \n",
    "            bearing3_channel = 5 if experiment == \"1\" else 3\n",
    "            experiments_data[experiment]['bearing3_values'].append(data[:,bearing3_channel])\n",
    "            experiments_data[experiment]['bearing3_keys'].append(file)\n",
    "            i+=1\n",
    "        \n",
    "    print(\"Converting NASA IMS dataset to spectrograms\")\n",
    "    return experiments_data,experiment_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting NASA IMS dataset to spectrograms\n"
     ]
    }
   ],
   "source": [
    "experiments_data,experiment_files = convert_nasa_experiments_to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bearing 3 failure labels\n",
    "\n",
    "from: https://github.com/Miltos-90/Failure_Classification_of_Bearings?tab=readme-ov-file\n",
    "\n",
    "\n",
    "#### Bearing 3\n",
    "* early: 2003.10.22.12.06.24 - 2003.11.01.21.41.44\n",
    "* normal: 2003.11.01.21.51.44 - 2003.11.22.09.16.56\n",
    "* suspect: 2003.11.22.09.26.56 - 2003.11.25.10.47.32\n",
    "* Inner race failure: 2003.11.25.10.57.32 - 2003.11.25.23.39.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have 6450 normal training samples of 64 x 64 stft spectrograms\n",
      "1\n",
      "1st_test.rar\n",
      "2\n",
      "2nd_test.rar\n",
      "3\n",
      "3rd_test.rar\n",
      "ims_bearings_train_exp1_b3_spectrograms.pt\n",
      "Readme Document for IMS Bearing Data.pdf\n",
      "we have 1645 normal training samples of 64 x 64 stft spectrograms\n",
      "1\n",
      "1st_test.rar\n",
      "2\n",
      "2nd_test.rar\n",
      "3\n",
      "3rd_test.rar\n",
      "ims_bearings_test_exp1_b3_spectrograms.pt\n",
      "ims_bearings_train_exp1_b3_spectrograms.pt\n",
      "Readme Document for IMS Bearing Data.pdf\n"
     ]
    }
   ],
   "source": [
    "def create_torch_nasa_spectrograms(name=\"train\", startfile = \"2003.11.01.21.51.44\", endfile= \"2003.11.22.09.16.56\", bearing=3, experiment=\"1\"):\n",
    "\n",
    "    index_start = experiments_data[experiment]['bearing%s_keys'%bearing].index(startfile)\n",
    "    index_end = experiments_data[experiment]['bearing%s_keys'%bearing].index(endfile)\n",
    "\n",
    "    training_files = experiment_files[experiment][index_start:index_end]\n",
    "    training_data = experiments_data[experiment]['bearing%s_values'%bearing][index_start:index_end]\n",
    "    training_data = np.stack(training_data) #each row is 1 second of data, taken every 10 minutes\n",
    "\n",
    "    #generate spectrograms\n",
    "    all_training_sample_spectrograms = []\n",
    "    for i in range(0, len(training_data)):\n",
    "        traiing_sample_window = create_windows(training_data[0], window_type='regular', window_length=64, overlap_length=10)\n",
    "        training_sample_spectrograms = create_stft_spectrograms(traiing_sample_window, stft_overlap=0, stft_window_length=64, fft_length=128)\n",
    "        all_training_sample_spectrograms.append(training_sample_spectrograms)\n",
    "\n",
    "    #create torch dataset\n",
    "    all_training_sample_spectrograms = np.vstack(all_training_sample_spectrograms)\n",
    "    all_training_sample_spectrograms = torch.from_numpy(all_training_sample_spectrograms).float()\n",
    "\n",
    "    print(\"we have %s normal training samples of %s x %s stft spectrograms\" % (all_training_sample_spectrograms.shape[0], all_training_sample_spectrograms.shape[1], all_training_sample_spectrograms.shape[2]))\n",
    "    #save the dataset\n",
    "    torch.save(all_training_sample_spectrograms, \"%s_%s_exp%s_b%s_spectrograms.pt\" % (DATASET_NAME,name,experiment,bearing))\n",
    "    os.system(\"ls\")\n",
    "\n",
    "\n",
    "create_torch_nasa_spectrograms(name=\"train\", startfile = \"2003.11.01.21.51.44\", endfile= \"2003.11.22.09.16.56\", bearing=3, experiment=\"1\")\n",
    "create_torch_nasa_spectrograms(name=\"test\", startfile = \"2003.11.22.09.26.56\", endfile= \"2003.11.25.10.47.32\", bearing=3, experiment=\"1\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai8x-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
